{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised NLP\n",
    "\n",
    "In this exercise, we will attempt to predict whether a sentence comes from _Alice in Wonderland_ by Lewis Carroll or _Persuasion_ by Jane Austen.  We'll perform NLP to create the input features for the model before using some run of the mill classifiers for the prediction.\n",
    "\n",
    "The main feature generation method that we'll use is **Bag of Words**.  Its simply counting how many times each word appears in every sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice[:int(len(alice)/10)])\n",
    "persuasion = text_cleaner(persuasion[:int(len(persuasion)/10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the texts cleaned, processed by spaCy, on combined into a nice DataFrame.  Now we can bag the words.  We'll use some functions to perform the bagging, but `SKlearn` has the `CountVectorizer` method that can do this too. Our focus will be on the 2000 most common lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>living</th>\n",
       "      <th>dispose</th>\n",
       "      <th>doorway</th>\n",
       "      <th>March</th>\n",
       "      <th>office</th>\n",
       "      <th>express</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>sight</th>\n",
       "      <th>delight</th>\n",
       "      <th>...</th>\n",
       "      <th>New</th>\n",
       "      <th>neighbour</th>\n",
       "      <th>esteem</th>\n",
       "      <th>bit</th>\n",
       "      <th>month</th>\n",
       "      <th>design</th>\n",
       "      <th>successive</th>\n",
       "      <th>Gloucester</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pair living dispose doorway March office express recommendation sight  \\\n",
       "0    0      0       0       0     0      0       0              0     0   \n",
       "1    0      0       0       0     0      0       0              0     0   \n",
       "2    0      0       0       0     0      0       0              0     0   \n",
       "3    0      0       0       0     0      0       0              0     0   \n",
       "4    0      0       0       0     0      0       0              0     0   \n",
       "\n",
       "  delight     ...     New neighbour esteem bit month design successive  \\\n",
       "0       0     ...       0         0      0   0     0      0          0   \n",
       "1       0     ...       0         0      0   0     0      0          0   \n",
       "2       0     ...       0         0      0   0     0      0          0   \n",
       "3       0     ...       0         0      0   0     0      0          0   \n",
       "4       0     ...       0         0      0   0     0      0          0   \n",
       "\n",
       "  Gloucester                                      text_sentence text_source  \n",
       "0          0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1          0  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2          0  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3          0                                      (Oh, dear, !)     Carroll  \n",
       "4          0                                      (Oh, dear, !)     Carroll  \n",
       "\n",
       "[5 rows x 1614 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>living</th>\n",
       "      <th>dispose</th>\n",
       "      <th>doorway</th>\n",
       "      <th>March</th>\n",
       "      <th>office</th>\n",
       "      <th>express</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>sight</th>\n",
       "      <th>delight</th>\n",
       "      <th>...</th>\n",
       "      <th>New</th>\n",
       "      <th>neighbour</th>\n",
       "      <th>esteem</th>\n",
       "      <th>bit</th>\n",
       "      <th>month</th>\n",
       "      <th>design</th>\n",
       "      <th>successive</th>\n",
       "      <th>Gloucester</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(You, need, not, be, afraid, ,, Miss, Elliot, ...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pair living dispose doorway March office express recommendation sight  \\\n",
       "309    0      0       0       0     0      0       0              0     0   \n",
       "\n",
       "    delight     ...     New neighbour esteem bit month design successive  \\\n",
       "309       0     ...       0         0      0   0     0      0          0   \n",
       "\n",
       "    Gloucester                                      text_sentence text_source  \n",
       "309          0  (You, need, not, be, afraid, ,, Miss, Elliot, ...      Austen  \n",
       "\n",
       "[1 rows x 1614 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts[word_counts['neglect'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BoW feature creation is complete.  Let's feed these into some models.  Once again, we're trying to predict which book a particular sentence came from.\n",
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9849624060150376\n",
      "\n",
      "Test set score: 0.8539325842696629\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obviously pretty severely overfit.  How do other models compare?\n",
    "\n",
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 1612) (266,)\n",
      "Training set score: 0.9624060150375939\n",
      "\n",
      "Test set score: 0.8707865168539326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', penalty='l2')\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a bit better than the RF model, but still overfit.  How about Gradient boosting?\n",
    "\n",
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9661654135338346\n",
      "\n",
      "Test set score: 0.8202247191011236\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosted trees seems to be the most overfit model.  Besides evaluating the models on training/test scores, another way to test their efficacy and generalization is to use a completely new work from a given author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model, new book\n",
    "\n",
    "Let's see if the model can differentiate between _Alice in Wonderland_ and a book it has not been trained on by Jane Austen, like _Emma_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to\n"
     ]
    }
   ],
   "source": [
    "# Loading and cleaning the text\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
    "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
    "emma = text_cleaner(emma[:(len(emma)//60)]) # Comparable length to Alice\n",
    "print(emma[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n"
     ]
    }
   ],
   "source": [
    "# Parse the text with spaCy\n",
    "emma_doc = nlp(emma)\n",
    "\n",
    "# Group into sentences\n",
    "emma_sents = [[sent, 'Austen'] for sent in emma_doc.sents]\n",
    "\n",
    "# Bag of Words\n",
    "emma_sentences = pd.DataFrame(emma_sents)\n",
    "emma_bow = bow_features(emma_sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the Persuasion data in the train test split with Emma data\n",
    "X_emma_test = np.concatenate((\n",
    "    X_train[y_train[y_train == 'Carroll'].index], \n",
    "    emma_bow.drop(['text_sentence', 'text_source'], 1)), axis=0)\n",
    "y_emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                        pd.Series(['Austen'] * emma_bow.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.7195121951219512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>158</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen      158       12\n",
       "Carroll      57       19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_emma_pred = lr.predict(X_emma_test)\n",
    "\n",
    "print('Test score: ', lr.score(X_emma_test, y_emma_test))\n",
    "pd.crosstab(y_emma_test, lr_emma_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so the model generalizes a bit.  It can differentiate between _Alice_ and an Austen work it has not seen before.  However, we don't know if it's good at identifying Austen's works, or _Alice_, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1:\n",
    "\n",
    "The original logistic regression scored 87% on the test set.  Let's add additional features and try to make it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df['sent_length'] = np.zeros(sentences[0].shape)\n",
    "    df['punct_length'] = np.zeros(sentences[0].shape)\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "            \n",
    "        # Count the number of Parts of Speech in each sentence\n",
    "        pos = [token.pos_ \n",
    "               for token in sentence \n",
    "               if (\n",
    "                   not token.is_punct \n",
    "                   and not token.is_stop \n",
    "                   and token.lemma_ in common_words)]\n",
    "        parts, counts = np.unique(np.array(pos), return_counts=True)\n",
    "        for j, p in enumerate(parts):\n",
    "            if p not in df.columns:\n",
    "                df[p] = np.zeros(sentences[0].shape)\n",
    "            df.loc[i, p] += counts[j]\n",
    "        \n",
    "        # Count the number of words in each sentence\n",
    "        sent_len = [token.lemma_ \n",
    "                         for token in sentence \n",
    "                         if not token.is_punct]\n",
    "        df.loc[i, \"sent_length\"] = len(sent_len)\n",
    "        \n",
    "        # Count the number of punctuation marks in each sentence\n",
    "        punct_len = [token for token in sentence if token.is_punct]\n",
    "        df.loc[i, 'punct_length'] = len(punct_len)\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>living</th>\n",
       "      <th>dispose</th>\n",
       "      <th>doorway</th>\n",
       "      <th>March</th>\n",
       "      <th>office</th>\n",
       "      <th>express</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>sight</th>\n",
       "      <th>delight</th>\n",
       "      <th>...</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>VERB</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>NUM</th>\n",
       "      <th>AUX</th>\n",
       "      <th>PART</th>\n",
       "      <th>DET</th>\n",
       "      <th>PUNCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair  living  dispose  doorway  March  office  express  recommendation  \\\n",
       "0     0       0        0        0      0       0        0               0   \n",
       "1     0       0        0        0      0       0        0               0   \n",
       "2     0       0        0        0      0       0        0               0   \n",
       "3     0       0        0        0      0       0        0               0   \n",
       "4     0       0        0        0      0       0        0               0   \n",
       "\n",
       "   sight  delight  ...    NOUN  PROPN  VERB  INTJ  ADP  NUM  AUX  PART  DET  \\\n",
       "0      0        0  ...    10.0    2.0   6.0   0.0  0.0  0.0  0.0   0.0  0.0   \n",
       "1      0        0  ...     8.0    2.0   6.0   0.0  0.0  0.0  0.0   0.0  0.0   \n",
       "2      0        0  ...     1.0    2.0   2.0   0.0  0.0  0.0  0.0   0.0  0.0   \n",
       "3      0        0  ...     0.0    0.0   0.0   1.0  0.0  0.0  0.0   0.0  0.0   \n",
       "4      0        0  ...     0.0    0.0   0.0   1.0  0.0  0.0  0.0   0.0  0.0   \n",
       "\n",
       "   PUNCT  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 1628 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word_counts = new_features(sentences, common_words)\n",
    "new_word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in addition to the common words, we have sentence length and sentence-wise part of speech count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature splits\n",
    "y_new = new_word_counts['text_source']\n",
    "X_new = np.array(new_word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = train_test_split(X_new, \n",
    "                                                    y_new,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9924812030075187\n",
      "Test score:  0.898876404494382\n"
     ]
    }
   ],
   "source": [
    "# New logistic regression model\n",
    "\n",
    "lr_new = LogisticRegression(C=20, solver='lbfgs', penalty='l2', max_iter=1000000)\n",
    "train = lr_new.fit(X_new_train, y_new_train)\n",
    "\n",
    "tr_score = lr_new.score(X_new_train, y_new_train)\n",
    "ts_score = lr_new.score(X_new_test, y_new_test)\n",
    "\n",
    "print('Training score: ', tr_score)\n",
    "print('Test score: ', ts_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding addtional features tended to drop the test score, however, after grid searching for `C` I found a solution which has a test score close to 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2:\n",
    "\n",
    "Test the model to find out if it is well trained on _Alice_, _Persuasion_, or _Austen_.  To do this, we'll grab a text from a different author and test it against all three of the previous texts; _Alice_, _Persuasion_, and _Emma_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use _The Ball and The Cross_ by Chesterton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball = gutenberg.raw('chesterton-ball.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[The Ball and The Cross by G.K. Chesterton 1909]\\n\\n\\nI. A DISCUSSION SOMEWHAT IN THE AIR\\n\\nThe flying ship of Professor Lucifer sang through the skies like\\na silver arrow; the bleak white steel of it, gleaming in the\\nbleak blue emptiness of the evening.  That it was far above the\\nearth was no expression for it; to the two men in it, it seemed\\nto be far above the stars.  The professor had himself invented\\nthe flying machine, and had also invented nearly everything in\\nit.  Every sort of tool or apparatus had, in consequence, to the\\nfull, that fantastic and distorted look which belongs to the\\nmiracles of science.  For the world of science and evolution is\\nfar more nameless and elusive and like a dream than the world of\\npoetry and religion; since in the latter images and ideas remain\\nthemselves eternally, while it is the whole idea of evolution\\nthat identities melt into each other as they do in a nightmare.\\n\\nAll the tools of Professor Lucifer were the ancient human tools\\ngone mad, grown into unrecognizable shapes, forgetful of their\\norigin, forgetful of their names.  That thing which looked like an\\nenormous key with three wheels was really a patent and very\\ndeadly revolver.  That object which seemed to be created by the\\nentanglement of two corkscrews was really the key.  The thing\\nwhich might have been mistaken for a tricycle turned upside-down\\nwas the inexpressibly important instrument to which the corkscrew\\nwas the key.  All these things, as I say, the professor had\\ninvented; he had invented everything in the flying ship, with the\\nexception, perhaps, of himself.  This he had been born too late\\nactually to inaugurate, but he believed at least, that he had\\nconsiderably improved it.\\n\\nThere was, however, another man on board, so to speak, at the\\ntime.  Him, also, by a curious coincidence, the professor had not\\ninvented, and him he had not even very greatly improved, though\\nhe had fished him up with a lasso out of his own back garden, in\\nWestern Bulgaria, with the pure object'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ball[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The flying ship of Professor Lucifer sang through the skies like a silver arrow; the bleak white steel of it, gleaming in the bleak blue emptiness of the evening.  That it was far above the earth was no expression for it; to the two men in it, it seemed to be far above the stars.  The professor had himself invented the flying machine, and had also invented nearly everything in it.  Every sort of tool or apparatus had, in consequence, to the full, that fantastic and distorted look which belongs to the miracles of science.  For the world of science and evolution is far more nameless and elusive and like a dream than the world of poetry and religion; since in the latter images and ideas remain themselves eternally, while it is the whole idea of evolution that identities melt into each other as they do in a nightmare.  All the tools of Professor Lucifer were the ancient human tools gone mad, grown into unrecognizable shapes, forgetful of their origin, forgetful of their names.  That thing which looked like an enormous key with three wheels was really a patent and very deadly revolver.  That object which seemed to be created by the entanglement of two corkscrews was really the key.  The thing which might have been mistaken for a tricycle turned upside-down was the inexpressibly important instrument to which the corkscrew was the key.  All these things, as I say, the professor had invented; he had invented everything in the flying ship, with the exception, perhaps, of himself.  This he had been born too late actually to inaugurate, but he believed at least, that he had considerably improved it.  There was, however, another man on board, so to speak, at the time.  Him, also, by a curious coincidence, the professor had not invented, and him he had not even very greatly improved, though he had fished him up with a lasso out of his own back garden, in Western Bulgaria, with the pure object of improving him.  He was an exceedingly holy man, almost entirely covered with white h'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning line breaks, title, Chapter letters 'I.', and chapter titles\n",
    "ball_clean = re.sub(r'\\n', ' ', ball)\n",
    "ball_clean = re.sub(\"[\\[].*?[\\]]\", \"\", ball_clean)\n",
    "ball_clean = re.sub(r'I\\.+?', '', ball_clean)\n",
    "ball_clean = re.sub(r'([A-Z ]+?  )', '', ball_clean)\n",
    "ball_clean[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortening the text length to better match the other works\n",
    "ball_clean = ball_clean[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n"
     ]
    }
   ],
   "source": [
    "# Parse the text with spaCy\n",
    "ball_doc = nlp(ball_clean)\n",
    "\n",
    "# Group into sentences\n",
    "ball_sents = [[sent, 'Chesterton'] for sent in ball_doc.sents]\n",
    "\n",
    "# Bag of Words\n",
    "ball_sentences = pd.DataFrame(ball_sents)\n",
    "ball_bow = bow_features(ball_sentences, common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned and processed _Ball_, let's combine it with each of the other three works to create three separate train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the Persuasion data in the train test split with Ball data\n",
    "X_AliceBall_test = np.concatenate((\n",
    "    X_train[y_train[y_train == 'Carroll'].index], \n",
    "    ball_bow.drop(['text_sentence', 'text_source'], 1)), axis=0)\n",
    "y_AliceBall_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                        pd.Series(['Chesterton'] * ball_bow.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Carroll', 'Chesterton'], dtype=object), array([ 76, 172]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_AliceBall_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Alice data with the Ball data\n",
    "X_PersBall = pd.concat((ball_bow.iloc[:129, :], word_counts.iloc[129:, :]))\n",
    "X_PersBall = X_PersBall.drop(['text_sentence','text_source'], 1)\n",
    "Y_PersBall = pd.concat((pd.Series(['Chesterton'] * 129), pd.Series(['Austen'] * 315)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PersBall_train, X_PersBall_test, Y_PersBall_train, Y_PersBall_test = train_test_split(X_PersBall,\n",
    "                                                                                       Y_PersBall,\n",
    "                                                                                       test_size=.4,\n",
    "                                                                                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Emma and Ball data\n",
    "X_BallEmma = pd.concat((ball_bow.iloc[:129, :], emma_bow))\n",
    "X_BallEmma = X_BallEmma.drop(['text_sentence','text_source'], 1)\n",
    "Y_BallEmma = pd.concat((pd.Series(['Chesterton'] * 129), pd.Series(['Austen'] * 170)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BallEmma_train, X_BallEmma_test, Y_BallEmma_train, Y_BallEmma_test = train_test_split(X_BallEmma,\n",
    "                                                                                       Y_BallEmma,\n",
    "                                                                                       test_size=.4,\n",
    "                                                                                       random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AliceBall Test score:  0.07661290322580645\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       Austen  Carroll\n",
       "row_0                      \n",
       "Carroll         57       19\n",
       "Chesterton     163        9"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AliceBall Results\n",
    "lr_AliceBall_pred = lr.predict(X_AliceBall_test)\n",
    "\n",
    "print('AliceBall Test score: ', lr.score(X_AliceBall_test, y_AliceBall_test))\n",
    "pd.crosstab(y_AliceBall_test, lr_AliceBall_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersBall Test score:  0.702247191011236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       Austen  Carroll\n",
       "row_0                      \n",
       "Austen         125        0\n",
       "Chesterton      48        5"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PersBall Results\n",
    "lr_PersBall_pred = lr.predict(X_PersBall_test)\n",
    "\n",
    "print('PersBall Test score: ', lr.score(X_PersBall_test, Y_PersBall_test))\n",
    "pd.crosstab(Y_PersBall_test, lr_PersBall_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BallEmma Test score:  0.5916666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       Austen  Carroll\n",
       "row_0                      \n",
       "Austen          71        3\n",
       "Chesterton      44        2"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BallEmma Results\n",
    "lr_BallEmma_pred = lr.predict(X_BallEmma_test)\n",
    "\n",
    "print('BallEmma Test score: ', lr.score(X_BallEmma_test, Y_BallEmma_test))\n",
    "pd.crosstab(Y_BallEmma_test, lr_BallEmma_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like our model is trained well on Jane Austen's Persuasion and generalizes fairly well to other works by Austen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
