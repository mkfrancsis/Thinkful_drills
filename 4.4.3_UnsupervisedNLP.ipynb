{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised NLP\n",
    "\n",
    "While supervised NLP allows us to transform text to digits and quantify the text, it does not allow us to gain an understanding of the text meaning.  We have the ability to count word frequency, sentence length, and the like, however, we can't tell that 'queen' is more similar to 'lady' than 'car'.  Also, we wouldn't be able to tell that synonyms are related instead of completely separate words.  \n",
    "\n",
    "Enter unsupervised NLP. The main goal of unsupervised NLP is to train a model to understand, at a semantic level, the corpus it has been trained on.  Instead of explicitly coding the rules of a language or corpus, we allow the model to learn the semantic rules of that text. The main method is **term frequency - inverse document frequency**, or **_tf-idf_** for short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "Term frequency - inverse document frequency is a method which weights the value of a particular lemma based on how frequently it appears in sentence and document.  Effectively, it will measure how important a word is to a sentence and the document as a whole.  Let's construct it's building blocks _term frequency_ and _inverse document frequency_.\n",
    "\n",
    "\n",
    "## Sentences to vectors\n",
    "We first need to parse text into a numerical vector form, similar to what we did in the supervised NLP exercise.  Consider the following sentences: \n",
    "\n",
    "1. \"The best Monty Python sketch is the one about the dead parrot,  I laughed so hard.\"\n",
    "2. \"I laugh when I think about Python's Ministry of Silly Walks sketch, it is funny, funny, funny, the best!\"\n",
    "3. \"Chocolate is the best ice cream dessert topping, with a great taste.\"\n",
    "4. \"The Lumberjack Song is the funniest Monty Python bit: I can't think of it without laughing.\"\n",
    "5. \"I would rather put strawberries on my ice cream for dessert, they have the best taste.\"\n",
    "6. \"The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\"\n",
    "\n",
    "Obviously, there are two main themes, comedy and ice cream.  How will we quantify these?\n",
    "\n",
    "If we parse these, removing stop words, reduce to lemmas, and discard words that only appear once, we can create the following term-document matrix.  Where by the columns represent each sentence in the \"document\" (loosely, the block of text evaluated, here a single sentence) and each row represents a term which passes through our decision gate.\n",
    "\n",
    "|    term   | 1 | 2 | 3 | 4 | 5 | 6 |\n",
    "|-----------|---|---|---|---|---|---|\n",
    "| Monty     | 1 | 0 | 0 | 1 | 0 | 0 |\n",
    "| Python    | 1 | 1 | 0 | 1 | 0 | 0 |\n",
    "| sketch    | 1 | 1 | 0 | 0 | 0 | 0 |\n",
    "| laugh     | 1 | 1 | 0 | 1 | 0 | 0 |\n",
    "| funny     | 0 | 3 | 0 | 1 | 0 | 0 |\n",
    "| best      | 1 | 1 | 1 | 0 | 1 | 0 |\n",
    "| ice cream | 0 | 0 | 1 | 0 | 1 | 1 |\n",
    "| dessert   | 0 | 0 | 1 | 0 | 1 | 0 |\n",
    "| taste     | 0 | 0 | 1 | 0 | 1 | 2 |\n",
    "\n",
    "The main take-aways from this table are that we have identified and quantified words that are important to each them; \"funny\" for comedy, \"taste\" for ice cream.  We also note that \"best\" is used indescriminantly across both each theme and the corpus.  We can reduce the dimensionality of this matrix by aggregating across each document and the collection (corpus) as a whole.\n",
    "\n",
    "\n",
    "## Document and collection frequency\n",
    "'Document frequency' counts how many documents (sentences, in this case) a word appears in.  'Collection frequency' counts how often a word appears, total, over the full collection (all sentences).  Let's calculate the df and cf for our sentence set:\n",
    "\n",
    "|     term  |df | cf| \n",
    "|-----------|---|---|\n",
    "| Monty     | 2 | 2 | \n",
    "| Python    | 3 | 3 | \n",
    "| sketch    | 2 | 2 | \n",
    "| laugh     | 3 | 3 | \n",
    "| funny     | 2 | 4 | \n",
    "| best      | 4 | 4 | \n",
    "| ice cream | 3 | 3 | \n",
    "| dessert   | 2 | 2 | \n",
    "| taste     | 3 | 4 | \n",
    "\n",
    "We have two different counts for each \"important\" lemma.  However, recall that high total occurances, such as \"best\", actually provide less information than words with fewer occurances, like \"funny\" or \"taste\".  These less common words have more specific context and will be more useful, so let's create a metric which follows this logic.\n",
    "\n",
    "\n",
    "## Inverse Document Frequency\n",
    "\n",
    "We will calculate the inverse document frequency (idf) as:\n",
    "\n",
    "$$ idf_t = \\log \\dfrac N{df_t} $$\n",
    "\n",
    "That is the log (base 2) of the ratio between the total number of documents (N) and the document frequency of each term ($df_t$).  The $idf_t$ weights represent which terms are most important across the entire collection of documents.\n",
    "\n",
    "|  term    |df | N | idf |\n",
    "|-----------|---|---|---|\n",
    "| Monty     | 2 | 6 | 1.585 |\n",
    "| Python    | 3 | 6 | 1 |\n",
    "| sketch    | 2 | 6 | 1.585 |\n",
    "| laugh     | 3 | 6 | 1 |\n",
    "| funny     | 2 | 6 | 1.585 |\n",
    "| best      | 4 | 6 | .585 |\n",
    "| ice cream | 3 | 6 | 1 |\n",
    "| dessert   | 2 | 6 | 1.585 |\n",
    "| taste     | 3 | 6 | 1 |\n",
    "\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "We can then multiply $idf_t$ by $tf_t,d$, the term frequency for each document (sentence, in this case) to arrive at the $tf-idf$.\n",
    "\n",
    "$$ tf-idf_t,d = (tf_t,d)(idf_t) $$\n",
    "\n",
    "|   term    | 1 | 2 | 3 | 4 | 5 | 6 |\n",
    "|-----------|---|---|---|---|---|---|\n",
    "| Monty     | 1.585 | 0 | 0 | 1.585 | 0 | 0 |\n",
    "| Python    | 1 | 1 | 0 | 1 | 0 | 0 |\n",
    "| sketch    | 1.585| 1.585 | 0 | 0 | 0 | 0 |\n",
    "| laugh     | 1 | 1 | 0 |  1 | 0 | 0 |\n",
    "| funny     | 0 | 4.755 | 0 | 1.585 | 0 | 0 |\n",
    "| best      | .585 | .585 | .585 | 0 | .585 | 0 |\n",
    "| ice cream | 0 | 0 | 1 | 0 | 1 | 1 |\n",
    "| dessert   | 0 | 0 | 1.585 | 0 | 1.585 | 0 |\n",
    "| taste     | 0 | 0 | 1 | 0 | 1 | 2 |\n",
    "\n",
    "Now we have a feature which incorporates both sentence-level and whole text-level information. From the table above, we note that, in sentence 2, \"funny\" has the highest $tf-idf$ score of the entire text.  We also see that while \"best\" is present in many sentences, it has a relatively low $tf-idf$ score because it is not very specific.\n",
    "\n",
    "\n",
    "## Considerations for $tf-idf$ Models\n",
    "\n",
    "* Which stop words to include or exclude\n",
    "* Should we use phrases ('Monty Python' instead of 'Monty' and 'Python') as terms\n",
    "* The threshold for infrequent words: Here, we excluded words that only occurred once.  In longer documents, it may be a good idea to set a higher threshold.\n",
    "* How many terms to keep.  We kept all the terms that fit our criteria (not a stop word, occurred more than once), but for bigger document collections or longer documents, this may create unfeasibly long vectors.  We may want to decide to only keep the 10,000 words with the highest collection frequency scores, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model\n",
    "\n",
    "This vector represenation of the text is called a Vector Space Model.  We can use this representation to compute the similarity between the trained sentences (or blocks of text) and a new sentence -- this is often used by search engines to match a query to possible results.\n",
    "\n",
    "To compute similarity, one has to first transform the new text into the trained vector space.  Then you calculated the cosine of the angle between the trained vectors and the new vector.  If the vectors are identical, then the angle is 0° and the cosine is 1.  Conversely, if the vectors are completely unrelated, the angle between them will be 90° and the cosine will be 0.  The cosine of the angle between the vectors represents a similarity score.\n",
    "\n",
    "\n",
    "# Latent Semantic Analysis\n",
    "\n",
    "While VSM is cool and useful, it struggles with synonyms and polysemy (\"I need a break\" vs \"I break things\").  It also has trouble with very large documents.  \n",
    "\n",
    "The solution is to reduce the dimensionality of the VSM with **Latent Semantic Analysis**, a form of PCA.  Specifically, the dimension reduction technique is called Singular Value Decomposition (SVD).  This differs from PCA in that the variables are not mean-centered and thus preserves the sparsity present within the VSM.  The output of SVD on the $tf-idf$ matrix is a cluster of terms that presumably reflect a topic.  Each sentence would then recieve a score for each topic, with higher scores indicating that it is more relevant to the topic.\n",
    "\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Ok, now let's try performing the $tf-idf$ and LSA on *Emma* by Jane Austen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mkfrancsis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')  # Need this to process the data\n",
    "from nltk.corpus import gutenberg\n",
    "import re\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ Emma by Jane Austen 1816 ]', 'VOLUME I', 'CHAPTER I', 'Emma Woodhouse , handsome , clever , and rich , with a comfortable home and happy disposition , seemed to unite some of the best blessings of existence ; and had lived nearly twenty - one years in the world with very little to distress or vex her .']\n"
     ]
    }
   ],
   "source": [
    "# Reading the data in by paragraphs, thus our \"document\" will be \n",
    "# full paragraphs, not just single sentences\n",
    "emma = gutenberg.paras('austen-emma.txt')\n",
    "\n",
    "emma_paras = []\n",
    "for paragraph in emma:\n",
    "    para = paragraph[0]\n",
    "    \n",
    "    # Cleaning the double dashes from the text\n",
    "    para = [re.sub(r'--', '', word) for word in para]\n",
    "    emma_paras.append(' '.join(para))\n",
    "    \n",
    "print(emma_paras[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf in sklearn\n",
    "\n",
    "SKlearn has a $tf-idf$ method available to use, along with a lengthy list of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 1948\n"
     ]
    }
   ],
   "source": [
    "# Need this for future comparisons to vectorized data\n",
    "X_train, X_test = train_test_split(emma_paras, \n",
    "                                   test_size=0.4, \n",
    "                                   random_state=0)\n",
    "\n",
    "# Hyperparameter decisions\n",
    "# max_df = 0.5, drops words that appear in more than half of all documents\n",
    "# min_df = 2, drops words that appear less than twice\n",
    "# use_idf = True, uses inverse document weighting\n",
    "# norm = u'l2', correction factor for document length\n",
    "# smooth_idf = True, Adds 1 to all document frequencies, eliminates div0 errors\n",
    "vectorizer = TfidfVectorizer(max_df = 0.5, \n",
    "                             min_df = 2, \n",
    "                             stop_words = 'english', \n",
    "                             lowercase = True, \n",
    "                             use_idf = True, \n",
    "                             norm = u'l2', \n",
    "                             smooth_idf = True)\n",
    "\n",
    "emma_paras_tfidf = vectorizer.fit_transform(emma_paras)\n",
    "print(f'Number of features {emma_paras_tfidf.get_shape()[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:  A very few minutes more , however , completed the present trial .\n",
      "\n",
      "tf-idf vector:  {'minutes': 0.7127450310382584, 'present': 0.701423210857947}\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf, X_test_tfidf = train_test_split(emma_paras_tfidf, \n",
    "                                               test_size = 0.4, \n",
    "                                               random_state = 0)\n",
    "\n",
    "# Reshape the output to human readable format\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "# Number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "# Creating a list of dictionaries to store the paragraphs in\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "\n",
    "# List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "    \n",
    "print('Original sentence: ', X_train[5])\n",
    "print('\\ntf-idf vector: ', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that because tf-idf is log base 2, and the $\\log_2(1) = 0$, that a score of 0 indicates that the word was present once in that sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD dimensionality reduction\n",
    "\n",
    "Our model has as shape of (2371, 1948).  We should definitely do some dimensionality reduction using SVD.  Remember that performing SVD on the tf-idf vectors is called Latent Semantic Analysis (LSA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of variance captured by all components:  45.21\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the SVD to create a reduced sample space of (n, 130)\n",
    "svd = TruncatedSVD(n_components = 130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "# Run the SVD on the training data\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "explained_var = svd.explained_variance_ratio_\n",
    "total_var = explained_var.sum()\n",
    "\n",
    "print(\"Percent of variance captured by all components: \", round(total_var * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Component 0\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "\" Oh !    0.999289\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Component 1\n",
      "\" You have made her too tall , Emma ,\" said Mr . Knightley .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.633420\n",
      "\" You get upon delicate subjects , Emma ,\" said Mrs . Weston smiling ; \" remember that I am here . Mr .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.582220\n",
      "\" I do not know what your opinion may be , Mrs . Weston ,\" said Mr . Knightley , \" of this great intimacy between Emma and Harriet Smith , but I think it a bad thing .\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.565064\n",
      "\" You are right , Mrs . Weston ,\" said Mr . Knightley warmly , \" Miss Fairfax is as capable as any of us of forming a just opinion of Mrs . Elton .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0.560316\n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.528317\n",
      "Mr . Knightley might quarrel with her , but Emma could not quarrel with herself .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0.523688\n",
      "\" Now ,\" said Emma , when they were fairly beyond the sweep gates , \" now Mr . Weston , do let me know what has happened .\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.513742\n",
      "\" In one respect , perhaps , Mr . Elton ' s manners are superior to Mr . Knightley ' s or Mr . Weston ' s .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.505682\n",
      "Emma found that it was not Mr . Weston ' s fault that the number of privy councillors was not yet larger .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.505581\n",
      "Mrs . Weston was acting no part , feigning no feelings in all that she said to him in favour of the event . She had been extremely surprized , never more so , than when Emma first opened the affair to her ; but she saw in it only increase of happiness to all , and had no scruple in urging him to the utmost . She had such a regard for Mr . Knightley , as to think he deserved even her dearest Emma ; and it was in every respect so proper , suitable , and unexceptionable a connexion , and in one respect , one point of the highest importance , so peculiarly eligible , so singularly fortunate , that now it seemed as if Emma could not safely have attached herself to any other creature , and that she had herself been the stupidest of beings in not having thought of it , and wished it long ago . How very few of those men in a rank of life to address Emma would have renounced their own home for Hartfield !    0.499073\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Component 2\n",
      "CHAPTER V      0.998642\n",
      "CHAPTER X      0.998642\n",
      "CHAPTER I      0.998642\n",
      "CHAPTER V      0.998642\n",
      "CHAPTER X      0.998642\n",
      "CHAPTER I      0.998642\n",
      "CHAPTER I      0.998642\n",
      "CHAPTER X      0.998642\n",
      "CHAPTER V      0.998642\n",
      "CHAPTER XII    0.997524\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Component 3\n",
      "\" Ah !      0.992902\n",
      "\" Ah !      0.992902\n",
      "\" Ah !      0.992902\n",
      "\" Ah !      0.992902\n",
      "\" Ah !      0.992902\n",
      "\" Ah !      0.992902\n",
      "\" Ah !      0.992902\n",
      "But ah !    0.992902\n",
      "\" Ah !      0.992902\n",
      "\" Ah !      0.992902\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "Component 4\n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .    0.650547\n",
      "\" Are you well , my Emma ?\"                                                    0.598865\n",
      "Emma demurred .                                                                0.598865\n",
      "Emma was silenced .                                                            0.587727\n",
      "At first it was downright dulness to Emma .                                    0.586806\n",
      "\" Emma , my dear Emma \"                                                        0.576602\n",
      "Emma could not resist .                                                        0.568299\n",
      "\" It is not now worth a regret ,\" said Emma .                                  0.556001\n",
      "\" For shame , Emma !                                                           0.543760\n",
      "\" No great variety of faces for you ,\" said Emma .                             0.491783\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Looking at the first 5 topics from the SVD\n",
    "para_by_component = pd.DataFrame(X_train_lsa, index=X_train)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'\\nComponent {i}')\n",
    "    print(para_by_component.loc[:, i].sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These groupings, or topics, seem to be well defined. Topics 0 and 3 contain exclamation text. Topic 2 is chapter headings. Topic 1 involves seemingly critical dialogue about or directed toward Emma.  Topic 4 involves actions by or related to Emma.\n",
    "\n",
    "\n",
    "# Sentence similarity\n",
    "\n",
    "We can also evaluate how similar sentences are to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key:\n",
      "0 That is _court_ .\n",
      "1 \" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"\n",
      "2 \" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .\n",
      "3 To restrain him as much as might be , by her own manners , she was immediately preparing to speak with exquisite calmness and gravity of the weather and the night ; but scarcely had she begun , scarcely had they passed the sweep - gate and joined the other carriage , than she found her subject cut up  her hand seized  her attention demanded , and Mr . Elton actually making violent love to her : availing himself of the precious opportunity , declaring sentiments which must be already well known , hoping  fearing  adoring  ready to die if she refused him ; but flattering himself that his ardent attachment and unequalled love and unexampled passion could not fail of having some effect , and in short , very much resolved on being seriously accepted as soon as possible .\n",
      "4 Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .\n",
      "5 A very few minutes more , however , completed the present trial .\n",
      "6 \" I am delighted to hear you speak so stoutly on the subject ,\" replied Emma , smiling ; \" but you do not mean to deny that there was a time  and not very distant either  when you gave me reason to understand that you did care about him ?\"\n",
      "7 \" Very well ; and if he had intended to give her one , he would have told her so .\"\n",
      "8 Some laughed , and answered good - humouredly .\n",
      "9 \" There appeared such a perfectly good understanding among them all \" he began rather quickly , but checking himself , added , \" however , it is impossible for me to say on what terms they really were  how it might all be behind the scenes .\n"
     ]
    }
   ],
   "source": [
    "# Computing similarity between the LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "\n",
    "# Only considering the first 10 sentences\n",
    "sim_matrix = pd.DataFrame(similarity, index=X_train).iloc[0:10, 0:10]\n",
    "\n",
    "ax = sns.heatmap(sim_matrix, \n",
    "                 yticklabels=range(10), \n",
    "                 cmap='magma_r')\n",
    "plt.show()\n",
    "\n",
    "# Creating a legend for the plot\n",
    "print('Sentence Key:')\n",
    "for i in range(10):\n",
    "    print(i, sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 10 sentences don't have much in common with each other, except sentences 8 and 9 which appear to describe affable relations between people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill 1: Test set\n",
    "\n",
    "Transform the test set using the trained LSA model and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Component 0\n",
      "\" Oh !\"        0.999289\n",
      "\" Oh !         0.999289\n",
      "\" Me ! oh !    0.999289\n",
      "\" Oh !         0.999289\n",
      "\" Oh no !      0.999289\n",
      "\" Oh !         0.999289\n",
      "\" Oh !         0.999289\n",
      "\" Oh !\"        0.999289\n",
      "\" Oh !         0.999289\n",
      "\" Oh !         0.999289\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Component 1\n",
      "\" Well , Mrs . Weston ,\" said Emma triumphantly when he left them , \" what do you say now to Mr . Knightley ' s marrying Jane Fairfax ?\"                                                                                                                                                                                                                                                                                                                                                                          0.677289\n",
      "Frank turned instantly to Emma , to claim her former promise ; and boasted himself an engaged man , which his father looked his most perfect approbation of  and it then appeared that Mrs . Weston was wanting _him_ to dance with Mrs . Elton himself , and that their business was to help to persuade him into it , which was done pretty soon . Mr . Weston and Mrs . Elton led the way , Mr . Frank Churchill and Miss Woodhouse followed .                                                                 0.603551\n",
      "In this walk Emma and Mr . Weston found all the others assembled ; and towards this view she immediately perceived Mr . Knightley and Harriet distinct from the rest , quietly leading the way .                                                                                                                                                                                                                                                                                                                  0.566721\n",
      "After tea , Mr . and Mrs . Weston , and Mr . Elton sat down with Mr . Woodhouse to cards .                                                                                                                                                                                                                                                                                                                                                                                                                        0.565105\n",
      "The result of this distress was , that , with a much more voluntary , cheerful consent than his daughter had ever presumed to hope for at the moment , she was able to fix her wedding - day  and Mr . Elton was called on , within a month from the marriage of Mr . and Mrs . Robert Martin , to join the hands of Mr . Knightley and Miss Woodhouse .                                                                                                                                                          0.556927\n",
      "\" Mrs . Weston ' s manners ,\" said Emma , \" were always particularly good .                                                                                                                                                                                                                                                                                                                                                                                                                                       0.549388\n",
      "\" He is a person I never think of from one month ' s end to another ,\" said Mr . Knightley , with a degree of vexation , which made Emma immediately talk of something else , though she could not comprehend why he should be angry .                                                                                                                                                                                                                                                                            0.547330\n",
      "Emma was more than half in hopes of Mr . Elton ' s having dropt a hint .                                                                                                                                                                                                                                                                                                                                                                                                                                          0.540684\n",
      "He had frightened her a little about Mr . Elton ; but when she considered that Mr . Knightley could not have observed him as she had done , neither with the interest , nor ( she must be allowed to tell herself , in spite of Mr . Knightley ' s pretensions ) with the skill of such an observer on such a question as herself , that he had spoken it hastily and in anger , she was able to believe , that he had rather said what he wished resentfully to be true , than what he knew any thing about .    0.534087\n",
      "\" Well ,\" said Emma , \" there is no disputing about taste . At least you admire her except her complexion .\"                                                                                                                                                                                                                                                                                                                                                                                                      0.532502\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Component 2\n",
      "CHAPTER XIX      0.998642\n",
      "CHAPTER XV       0.998642\n",
      "CHAPTER XV       0.998642\n",
      "CHAPTER XV       0.998642\n",
      "CHAPTER XVIII    0.998642\n",
      "CHAPTER XVIII    0.998642\n",
      "CHAPTER XVIII    0.998642\n",
      "CHAPTER XII      0.997524\n",
      "CHAPTER XII      0.997524\n",
      "CHAPTER XVII     0.997497\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Component 3\n",
      "\" Ah !\"    0.992902\n",
      "\" Ah !\"    0.992902\n",
      "\" Ah !     0.992902\n",
      "\" Ah !     0.992902\n",
      "\" Ah !     0.992902\n",
      "\" Ah !     0.992902\n",
      "\" Ah !     0.992902\n",
      "\" Ah !     0.992902\n",
      "\" Ah !     0.992902\n",
      "\" Ah !     0.992902\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "Component 4\n",
      "\" No , no ,\" said Emma , \" it will not reckon low .                                                             0.632053\n",
      "Nobody had any information to give ; and , after a few more wonderings , Emma said ,                            0.629507\n",
      "\" Well ,\" said Emma , \" there is no disputing about taste . At least you admire her except her complexion .\"    0.620690\n",
      "Emma had done .                                                                                                 0.598865\n",
      "\" My Emma !\"                                                                                                    0.598865\n",
      "\" Emma !\"                                                                                                       0.598865\n",
      "Emma wondered on what , of all the medley , she would fix .                                                     0.594817\n",
      "\" Emma ,\" said she , \" this paper is worse than I expected .                                                    0.593037\n",
      "\" And I do envy him , Emma .                                                                                    0.592420\n",
      "\" No ,\" said Emma , laughing ; \" but perhaps there might be some made to his coming back again .                0.556238\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Transforming the test data\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "\n",
    "# Looking at the first 5 topics from the SVD\n",
    "para_by_component = pd.DataFrame(X_test_lsa, index=X_test)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'\\nComponent {i}')\n",
    "    print(para_by_component.loc[:, i].sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test sentences seem to match the same type of sentences we saw from the training data.  That's good news!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill 2: Tweaking the tf-idf model\n",
    "\n",
    "Play with the tf-idf model and describe the resulting changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 1575\n"
     ]
    }
   ],
   "source": [
    "# Removing the stop word list\n",
    "# Increasing the max_df to 0.7\n",
    "# Increasing min_df to 3\n",
    "vectorizer2 = TfidfVectorizer(max_df = 0.7,\n",
    "                             min_df = 3, \n",
    "                             stop_words = None, \n",
    "                             lowercase = True, \n",
    "                             use_idf = True, \n",
    "                             norm = u'l2', \n",
    "                             smooth_idf = True)\n",
    "\n",
    "emma_paras_tfidf2 = vectorizer2.fit_transform(emma_paras)\n",
    "print(f'Number of features {emma_paras_tfidf2.get_shape()[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreased the number of original features by ~400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:  A very few minutes more , however , completed the present trial .\n",
      "\n",
      "tf-idf vector:  {'ideas': 0.47569934416254367, 'lose': 0.46814294994025785, 'fell': 0.42643765695823255, 'importance': 0.3288719371916576, 'does': 0.4221770789966193, 'respectable': 0.24059697181427692, 'questioned': 0.1686004067729988}\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf2, X_test_tfidf2 = train_test_split(emma_paras_tfidf2, \n",
    "                                               test_size = 0.4, \n",
    "                                               random_state = 0)\n",
    "\n",
    "# Reshape the output to human readable format\n",
    "X_train_tfidf2_csr = X_train_tfidf2.tocsr()\n",
    "\n",
    "# Number of paragraphs\n",
    "n = X_train_tfidf2_csr.shape[0]\n",
    "\n",
    "# Creating a list of dictionaries to store the paragraphs in\n",
    "tfidf2_bypara = [{} for _ in range(0,n)]\n",
    "\n",
    "# List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, j in zip(*X_train_tfidf2_csr.nonzero()):\n",
    "    tfidf2_bypara[i][terms[j]] = X_train_tfidf2_csr[i, j]\n",
    "    \n",
    "print('Original sentence: ', X_train[5])\n",
    "print('\\ntf-idf vector: ', tfidf2_bypara[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many more words are included as vectors now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of variance captured by all components:  53.35\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the SVD to create a reduced sample space of (n, 130)\n",
    "svd = TruncatedSVD(n_components = 130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "# Run the SVD on the training data\n",
    "X_train2_lsa = lsa.fit_transform(X_train_tfidf2)\n",
    "\n",
    "explained_var = svd.explained_variance_ratio_\n",
    "total_var = explained_var.sum()\n",
    "\n",
    "print(\"Percent of variance captured by all components: \", round(total_var * 100, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Component 0\n",
      "Mrs . Weston was acting no part , feigning no feelings in all that she said to him in favour of the event . She had been extremely surprized , never more so , than when Emma first opened the affair to her ; but she saw in it only increase of happiness to all , and had no scruple in urging him to the utmost . She had such a regard for Mr . Knightley , as to think he deserved even her dearest Emma ; and it was in every respect so proper , suitable , and unexceptionable a connexion , and in one respect , one point of the highest importance , so peculiarly eligible , so singularly fortunate , that now it seemed as if Emma could not safely have attached herself to any other creature , and that she had herself been the stupidest of beings in not having thought of it , and wished it long ago . How very few of those men in a rank of life to address Emma would have renounced their own home for Hartfield !                                                                                                            0.758706\n",
      "This was the amount of the whole story , of his communication and of Harriet ' s as soon as she had recovered her senses and speech . He dared not stay longer than to see her well ; these several delays left him not another minute to lose ; and Emma engaging to give assurance of her safety to Mrs . Goddard , and notice of there being such a set of people in the neighbourhood to Mr . Knightley , he set off , with all the grateful blessings that she could utter for her friend and herself .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0.747522\n",
      "To restrain him as much as might be , by her own manners , she was immediately preparing to speak with exquisite calmness and gravity of the weather and the night ; but scarcely had she begun , scarcely had they passed the sweep - gate and joined the other carriage , than she found her subject cut up  her hand seized  her attention demanded , and Mr . Elton actually making violent love to her : availing himself of the precious opportunity , declaring sentiments which must be already well known , hoping  fearing  adoring  ready to die if she refused him ; but flattering himself that his ardent attachment and unequalled love and unexampled passion could not fail of having some effect , and in short , very much resolved on being seriously accepted as soon as possible .                                                                                                                                                                                                                                                 0.692159\n",
      "The charming Augusta Hawkins , in addition to all the usual advantages of perfect beauty and merit , was in possession of an independent fortune , of so many thousands as would always be called ten ; a point of some dignity , as well as some convenience : the story told well ; he had not thrown himself away  he had gained a woman of 10 , 000 l . or thereabouts ; and he had gained her with such delightful rapidity  the first hour of introduction had been so very soon followed by distinguishing notice ; the history which he had to give Mrs . Cole of the rise and progress of the affair was so glorious  the steps so quick , from the accidental rencontre , to the dinner at Mr . Green ' s , and the party at Mrs . Brown ' s  smiles and blushes rising in importance  with consciousness and agitation richly scattered  the lady had been so easily impressed  so sweetly disposed  had in short , to use a most intelligible phrase , been so very ready to have him , that vanity and prudence were equally contented .    0.686820\n",
      "Mr . Weston meanwhile , perfectly unsuspicious of the indignation he was exciting , happy and cheerful as usual , and with all the right of being principal talker , which a day spent anywhere from home confers , was making himself agreeable among the rest ; and having satisfied the inquiries of his wife as to his dinner , convincing her that none of all her careful directions to the servants had been forgotten , and spread abroad what public news he had heard , was proceeding to a family communication , which , though principally addressed to Mrs . Weston , he had not the smallest doubt of being highly interesting to every body in the room .                                                                                                                                                                                                                                                                                                                                                                                0.675189\n",
      "She felt all the honest pride and complacency which her alliance with the present and future proprietor could fairly warrant , as she viewed the respectable size and style of the building , its suitable , becoming , characteristic situation , low and sheltered  its ample gardens stretching down to meadows washed by a stream , of which the Abbey , with all the old neglect of prospect , had scarcely a sight  and its abundance of timber in rows and avenues , which neither fashion nor extravagance had rooted up . The house was larger than Hartfield , and totally unlike it , covering a good deal of ground , rambling and irregular , with many comfortable , and one or two handsome rooms . It was just what it ought to be , and it looked what it was  and Emma felt an increasing respect for it , as the residence of a family of such true gentility , untainted in blood and understanding . Some faults of temper John Knightley had ; but Isabella had connected herself unexceptionably .                                0.673444\n",
      "This was a pleasure which perhaps the whole day ' s visit might not afford , which certainly did not belong to the present half - hour ; but the very sight of Mrs . Weston , her smile , her touch , her voice was grateful to Emma , and she determined to think as little as possible of Mr . Elton ' s oddities , or of any thing else unpleasant , and enjoy all that was enjoyable to the utmost .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.670803\n",
      "Emma could not forgive her ; but as neither provocation nor resentment were discerned by Mr . Knightley , who had been of the party , and had seen only proper attention and pleasing behaviour on each side , he was expressing the next morning , being at Hartfield again on business with Mr . Woodhouse , his approbation of the whole ; not so openly as he might have done had her father been out of the room , but speaking plain enough to be very intelligible to Emma .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.665374\n",
      "\" Why , to own the truth ,\" cried Miss Bates , who had been trying in vain to be heard the last two minutes , \" if I must speak on this subject , there is no denying that Mr . Frank Churchill might have  I do not mean to say that he did not dream it  I am sure I have sometimes the oddest dreams in the world  but if I am questioned about it , I must acknowledge that there was such an idea last spring ; for Mrs . Perry herself mentioned it to my mother , and the Coles knew of it as well as ourselves  but it was quite a secret , known to nobody else , and only thought of about three days .                                                                                                                                                                                                                                                                                                                                                                                                                                        0.664608\n",
      "Emma saw Mrs . Weston ' s surprize , and felt that it must be great , at an address which , in words and manner , was assuming to himself the right of first interest in her ; and as for herself , she was too much provoked and offended to have the power of directly saying any thing to the purpose .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               0.661059\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Component 1\n",
      "\" Oh !     0.999056\n",
      "\" Oh !\"    0.999056\n",
      "\" Oh !     0.999056\n",
      "\" Oh !     0.999056\n",
      "\" Oh !     0.999056\n",
      "\" Oh !\"    0.999056\n",
      "Oh !       0.999056\n",
      "\" Oh !     0.999056\n",
      "\" Oh !     0.999056\n",
      "\" Oh !\"    0.999056\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Component 2\n",
      "\" Indeed you injure me if you suppose me unconvinced .                                                                                                                                                                        0.510454\n",
      "\" You will not ask me what is the point of envy . You are determined , I see , to have no curiosity . You are wise  but _I_ cannot be wise .                                                                                  0.506550\n",
      "\" He appears rough to you ,\" said Emma , \" because you are so very gentle yourself ; but if you could compare him with other papas , you would not think him rough .                                                          0.489195\n",
      "\" You surprize me !                                                                                                                                                                                                           0.479123\n",
      "\" You have some news to hear , now you are come back , that will rather surprize you .\"                                                                                                                                       0.478501\n",
      "\" Thank you , dear Miss Woodhouse , you are all kindness . It is impossible to say  Yes , indeed , I quite understand  dearest Jane ' s prospects  that is , I do not mean . But she is charmingly recovered . How is Mr .    0.468608\n",
      "\" You would not have encouraged me , then , if you had understood me ?                                                                                                                                                        0.459167\n",
      "\" I am very glad you did , and that you communicated it to me .                                                                                                                                                               0.456025\n",
      "\" You will soon be cooler , if you sit still ,\" said Emma .                                                                                                                                                                   0.434984\n",
      "\" Come ,\" said she , \" I will tell you something , in return for what you have told me .                                                                                                                                      0.433919\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Component 3\n",
      "CHAPTER I      0.998573\n",
      "CHAPTER V      0.998573\n",
      "CHAPTER X      0.998573\n",
      "CHAPTER I      0.998573\n",
      "CHAPTER X      0.998573\n",
      "CHAPTER V      0.998573\n",
      "CHAPTER V      0.998573\n",
      "CHAPTER X      0.998573\n",
      "CHAPTER I      0.998573\n",
      "CHAPTER XII    0.997410\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "Component 4\n",
      "\" Ah !     0.981653\n",
      "\" Ah !     0.981653\n",
      "\" Ah !     0.981653\n",
      "\" Ah !\"    0.981653\n",
      "\" Ah !     0.981653\n",
      "\" Ah !     0.981653\n",
      "\" Ah !     0.981653\n",
      "\" Ah !     0.981653\n",
      "\" Ah !     0.981653\n",
      "\" Ah !     0.981653\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Looking at the first 5 topics from the SVD\n",
    "para_by_component = pd.DataFrame(X_train2_lsa, index=X_train)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'\\nComponent {i}')\n",
    "    print(para_by_component.loc[:, i].sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key:\n",
      "0 That is _court_ .\n",
      "1 \" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"\n",
      "2 \" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .\n",
      "3 To restrain him as much as might be , by her own manners , she was immediately preparing to speak with exquisite calmness and gravity of the weather and the night ; but scarcely had she begun , scarcely had they passed the sweep - gate and joined the other carriage , than she found her subject cut up  her hand seized  her attention demanded , and Mr . Elton actually making violent love to her : availing himself of the precious opportunity , declaring sentiments which must be already well known , hoping  fearing  adoring  ready to die if she refused him ; but flattering himself that his ardent attachment and unequalled love and unexampled passion could not fail of having some effect , and in short , very much resolved on being seriously accepted as soon as possible .\n",
      "4 Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .\n",
      "5 A very few minutes more , however , completed the present trial .\n",
      "6 \" I am delighted to hear you speak so stoutly on the subject ,\" replied Emma , smiling ; \" but you do not mean to deny that there was a time  and not very distant either  when you gave me reason to understand that you did care about him ?\"\n",
      "7 \" Very well ; and if he had intended to give her one , he would have told her so .\"\n",
      "8 Some laughed , and answered good - humouredly .\n",
      "9 \" There appeared such a perfectly good understanding among them all \" he began rather quickly , but checking himself , added , \" however , it is impossible for me to say on what terms they really were  how it might all be behind the scenes .\n"
     ]
    }
   ],
   "source": [
    "# Computing similarity between the LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train2_lsa) * np.asmatrix(X_train2_lsa).T)\n",
    "\n",
    "# Only considering the first 10 sentences\n",
    "sim_matrix = pd.DataFrame(similarity, index=X_train).iloc[0:10, 0:10]\n",
    "\n",
    "ax = sns.heatmap(sim_matrix, \n",
    "                 yticklabels=range(10), \n",
    "                 cmap='magma_r')\n",
    "plt.show()\n",
    "\n",
    "# Creating a legend for the plot\n",
    "print('Sentence Key:')\n",
    "for i in range(10):\n",
    "    print(i, sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
